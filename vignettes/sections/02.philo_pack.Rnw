\section{Philosophy of \pack}

\pack~aims to facilitate the implementation of statistical methods commoly foind in \PPB~programmes.
The statistical procedures are based on frequentist and bayesian approaches.

\subsection{What is \PPB ?}

!!! TO DO !!!

\subsection{Function relations in \pack}

\pack~is divided into two sets of functions:

\begin{itemize}
\item Hidden functions
\item Used functions
\end{itemize}

In this vignette, we only used examples with used functions.
Nevertheless, hidden functions could be used in other context to answer specific questions.
Figure~\ref{function_relations} displays these functions and their relations.
Table~\ref{function_descriptions} gives a quick description of each function.
You can have more information for each function by typing \texttt{?function\_name} in your \R~session.


\begin{figure}[H]
\begin{center}
\includegraphics[width=\textwidth]{PBBstats_function_relations}
\end{center}
\caption{Function relations in \pack.
Functions related to model \ref{model1} are in red.
Functions related to model \ref{model2} are in orange.
Functions related to both models are in black.
}
\label{function_relations}
\end{figure}

\begin{table}[t]
\begin{tabular}{cp{.6\textwidth}}

\hline
\textbf{function name} & \textbf{description} \\

\hline
\hline

\texttt{MC} & Run model~\ref{model1} to get mean comparisons (MC) on each environment of the network.\\
\hline

\texttt{FWH} & Run model~\ref{model2} to get main germplasm, environment and sensitivity effects over the network. \\
\hline

\texttt{analyse.outputs} & Check with plots if the model went well based ont the Gelman-Rubin test and plots of posteriors distributions (see section \ref{section_bayes}). It is important to run this step before going ahead in the analysis otherwise you may make mistakes in the interpretation of the results \\
\hline

\texttt{get.mean.comparisons} & Get mean comparisons for a given parameter two by two or to a given threshold based on MCMC outputs \\
\hline

\texttt{get.parameter.groups} & Get groups of parameters based on multivariate analysis \\
\hline

\texttt{cross.validation.FWH} & Run complete cross vlidation with model~\ref{model2} \\
\hline

\texttt{predict.the.past} & Estimate value of a germplasm in an environment based on the FWH model. \\
\hline

\texttt{get.ggplot} & Get ggplot objects to visualize output from the analysis \\
\hline

\hline

\texttt{get.env.info} & Get regional farms data and satellite farms data \\
\hline

\texttt{comp.parameters} & Get parameter comparisons two by two or to a given threshold based on MCMC outputs \\
\hline

\texttt{get.significant.groups} & Get significant groups of differences for a set of parameters based on MCMC outputs \\
\hline

\texttt{get.at.least.X.groups} & Get the value of type one error needed to have X groups. \\
\hline


\end{tabular}
\caption{Function descriptions in \pack.}
\label{function_descriptions}
\end{table}



\subsection{Frequentist statistics}



\subsection{Bayesian statistics}
\label{section_bayes}

The analyses performed in \pack~are based on Bayesian statistics.

Bayesian statistics are based on the Bayes theorem:

\begin{displaymath}
Pr(\theta|y) \propto Pr(\theta) Pr(y|\theta)
\end{displaymath}

with 
$Pr(\theta|y)$ the posterior, 
$Pr(y|\theta)$ the likelihood and 
$Pr(\theta)$ the prior.

The parameters' distribution, knowing the data (the posterior), is proportional to the distribution \textit{a  priori} (the prior) $\times$ the information brought by the data (the likelihood).

The more information (i.e. the larger the data set and the better the model fits the data), the less the prior would be of importance.
If the priors equal the posteriors, it means that there is not enough data or the model does not fit the data.


Bayesian inference is based on the posterior distribution of model parameters.
This distribution could not be calculated explicitely for the hierarchical model used in here (see section~\ref{section_model1} and section~\ref{section_model2}) but could be estimated using Markov Chain and Monte Carlo (MCMC) methods.

These methods simulate values of model parameters according to a Markov chain that converges to the posterior distribution of model parameters \citep{robert_bayesian_2001}.

MCMC methods were implemented using \texttt{JAGS} by the \texttt{R} package \texttt{rjags} that performed Gibbs sampling \citep{robert_bayesian_2001}.
Two MCMC chains were run independently to test for convergence using the Gelman-Rubin test.
This test was based on the variance within and between the chains \citep{gelman_inference_1992}.

A burn-in and lots of iterations were needed in the MCMC procedure.
In our case, the burn-in had 1000 iterations, then 100 000 iterations are done by default\footnote{You can change it with the argument \texttt{nb\_iterations} in functions \texttt{MC} and \texttt{FWH}} with a thinning interval of 10 to reduce autocorrelations between samples, so that 10 000 samples were available for inference for each chain by default\footnote{There are \texttt{nb\_iterations}/10 values for each chain. This can be changed with the \texttt{thin} argument of the functions.}.
 
The final distribution of a posterior is the concatenation of the two MCMC chains: 20 000 samples.

\subsection{Let's go!}
To continue, load the package:
<<message=TRUE,cache=FALSE>>=
library(PPBstats)
@
and download from internet the data used in this vignette (this is useful to earn lots of time!) :

<<message=FALSE,cache=FALSE,eval=FALSE>>=
get.PPBstats.data() # not run
# |=======================================================================| 100%
# The data are downloaded in ./data_PPBstats/ 
# You can now load the data, for example load("./data_PPBstats/out1.Rdata").
@


%The example in this vignette were performed with a computer with 4 Gb of memory and the following processor : Intel(R) Core(TM) i5-4210M CPU @ 2.60GHz.
%This gives an idea about memory and processor needed to run the analysis.

