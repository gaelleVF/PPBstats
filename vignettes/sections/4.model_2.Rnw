\section{At the network level : model~\ref{model2} to analyse $G \times E$ interaction in the network of farms }
\label{section_model2}

\subsection{The model}

The phenotypic value $Y_{ij}$ for a given variable $Y$, germplasm $i$ and environment $j$, was modeled as :

\begin{displaymath}
Y_{ij} = \alpha_{i} + \theta_{j} + \eta_{i}\theta_{j} + \varepsilon_{ij} ; \quad \varepsilon_{ij} \sim \mathcal{N} (0,\sigma^2_{e}),
\label{modele_gxe}
\end{displaymath}

for $i = 1,\ldots, I$ and $j = 1,\ldots, J$, where 
$I$ was the number of germplasms, 
$J$ was the number of environments,
$\alpha_{i}$ was the main effect of germplasm $i$,
$\theta_{j}$ was the main effect of environnment $j$,
$\varepsilon_{ij}$ was the residual and 
$\mathcal{N} (0,\sigma^2_{e})$ was the normal distribution with mean 0 and variance $\sigma^2_{e}$.
The interaction between germplasm $i$ and environment $j$ was divided into a multiplicative term $\eta_{i}\theta_{j}$ and a remaining term that contributed to the residual $\varepsilon_{ij}$.

This model was written as :

\begin{equation}
Y_{ij}  = \alpha_{i} + \beta_{i} \theta_{j} + \varepsilon_{ij}; \quad \varepsilon_{ij} \sim \mathcal{N} (0,\sigma_{\varepsilon}),
	\label{model2}
\end{equation}

Where $\beta_{i} = (1 + \eta_{i})$ was the sensitivity of germplasm $i$ to environments.
This model is known as the Finlay Wilkinson model or as joint regression \citep{finlay_analysis_1963}.
Germplasm sensitivities quantified the stability of germplasm performances over environments.
The average sensitivity was equal to 1 so that a gemplasm with $\beta_{i} > 1$ ($\beta_{i} < 1$) was more (less) sensitive to environments than a germplasm with the average sensitivity \citep{nabugoomu_analysis_1999}.

Given the high disequilibrium of the data and the large amount of data, we decided to implement this model with a hierarchical Bayesian approach.
In the following, this Hierarchical Finlay Wilkinson model was denoted by HFW.

We used hierarchical priors for $\alpha_i$, $\beta_i$ and $\theta_j$ and a vague prior for $\sigma_{\varepsilon}$.

\begin{displaymath}
\alpha_{i} \sim \mathcal{N} (\mu,\sigma^2_{\alpha}), \quad 
\beta_{i} \sim \mathcal{N} (1,\sigma^2_{\beta}), \quad 
\theta_{j} \sim \mathcal{N} (0,\sigma^2_{\theta}), \quad 
\sigma^{-2}_{\varepsilon} \sim \mathcal{G}amma (10^{-6},10^{-6}),
\end{displaymath}

where $\mu$, $\sigma^2_{\alpha}$, $\sigma^2_{\beta}$ and $\sigma^2_{\theta}$ were unknown parameters.
The mean of $\beta_i$ was set to 1 \citep{nabugoomu_analysis_1999}.


Then, we placed weakly-informative priors on the hyperparmeters  $\mu$, $\sigma^2_{\alpha}$, $\sigma^2_{\beta}$ and $\sigma^2_{\theta}$:

\begin{displaymath}
\mu \sim \mathcal{N} (\nu,\nu^2), \quad 
\sigma_{\alpha} \sim \mathcal{U}niforme (0,\nu), \quad 
\sigma_{\beta} \sim \mathcal{U}niforme (0,1), \quad 
\sigma_{\theta} \sim \mathcal{U}niforme (0,\nu),
\end{displaymath}

where $\nu$ was the arithmetic mean of the data : $\nu = \sum_{ij} {Y_{ij}/n}$ where $n$ was the number of observations.
Uniform priors were used for $\sigma^2_{\alpha}$, $\sigma^2_{\beta}$ and $\sigma^2_{\theta}$ to reduce the influence of these priors on posterior results \citep{gelman__2006}.
The support of these priors took account of the prior knowledge that $\sigma^2_{\alpha}$, $\sigma^2_{\beta}$ and $\sigma^2_{\theta}$ were expected to be respectively smaller than $\nu$, 1, $\nu$. \\

Initial values for each chain were taken randomly except for $\mu$, $\sigma_{\alpha}$ and $\sigma_{\theta}$ whose initial values were equal to their posterior median from additive model (i.e. model \ref{model2} with $\forall i, \beta_{i}=1$). \\


The main parameter of interest were 
germplasm main effects ($\alpha_{i}, i = 1,\ldots, I$), 
environment main effects ($\theta_{j}, j = 1,\ldots, J$) and 
germplasm sensitivities ($\beta_{i}, i = 1,\ldots, I$).
For $\alpha_i$, the average posterior response of each germplasm over the environments of the network was considered:

\begin{displaymath}
\gamma_i = \alpha_i + \beta_{i} \bar{\theta},
\end{displaymath}
where
$\bar{\theta} = \sum_{}^{J} \theta_j/J$.

To simplify, the $\alpha_i$ notation is kept instead of $\gamma_i$ (i.e. $\alpha_i = \gamma_i$).
But keep in mind it has been corrected.

\subsection{With \pack}

For model~\ref{model2}, you can follow these steps (Figure \ref{function_relations}):

\begin{enumerate}
\item Run the model with \texttt{FWH}
\item Analyse model outputs with graphs to kow if you can continue the analysis with \texttt{analyse.outputs}
\item Perform cross validation studies with \texttt{cross.validation.FWH} in order to assess the quality of the model
\item Get mean comparisons for each factor with \texttt{get.mean.comparisons} and \texttt{get.ggplot}
\item Get groups of parameters for $\alpha$, $\beta$ and $\theta$ with \texttt{get.parameters.groups} and \texttt{get.ggplot}
\item Predict the past with \texttt{predict.the.past} and \texttt{get.ggplot}
\end{enumerate}

Let's get the data.
The values for $\alpha_i$, $\beta_i$, $\theta_j$ are the real value taken to create the dataset for y1.
This dataset is representative of data you can get in a PPB programme.

<<message=TRUE,cache=FALSE>>=
data(PPBdata2)
head(PPBdata2)
@


\subsubsection{Run the model}

To run model \ref{model2} on the dataset, used the function \texttt{FWH} (which stands for Finlay Wilkinson Hierarchical).
You can run it on one variable.
Here it is on thousand kernel weight (tkw)

By default, \texttt{FWH} returns posteriors for 
$\alpha_i$ (\texttt{return.alpha = TRUE}),
$\sigma_{\alpha}$ (\texttt{return.sigma\_alpha = TRUE}),
$\beta_i$ (\texttt{return.beta = TRUE}),
$\sigma_{\beta}$ (\texttt{return.sigma\_beta = TRUE}),
$\theta_j$ (\texttt{return.theta = TRUE}),
$\sigma_{\theta}$ (\texttt{return.sigma\_theta = TRUE}) and
$\sigma_{\epsilon}$ (\texttt{return.sigma\_epsilon = TRUE}).
You can also get $\epsilon_{ij}$ with \texttt{return.epsilon = TRUE}.

By default, DIC is not display, you may want this value to compare to other model (\texttt{DIC = TRUE}).
DIC criterion is a generalization of the AIC criterion that can be used for hierarchical models \citep{spiegelhalter_bayesian_2002}.
The smaller the DIC value, the better the model \citep{plummer_penalized_2008}.

<<message=TRUE,cache=FALSE>>=
# out.model2 = FWH(data = PPBdata2, variable = "y1", return.epsilon = TRUE)
#Run additive model ...
#Compiling model graph
#   Resolving undeclared variables
#   Allocating nodes
#   Graph Size: 9759
#
#Initializing model
#
#  |++++++++++++++++++++++++++++++++++++++++++++++++++| 100%
#  |**************************************************| 100%
#  |**************************************************| 100%
#Run FWH model ...
#Compiling model graph
#   Resolving undeclared variables
#   Allocating nodes
#   Graph Size: 14677
#
#Initializing model
#
#  |++++++++++++++++++++++++++++++++++++++++++++++++++| 100%
#  |**************************************************| 100%
#  |**************************************************| 100%
#  |**************************************************| 100%

load("./data_PPBstats/out.model2.RData") # To save time
@

It may be useful to see which germplasm were not use in the analysis because they were in only one environment.

<<message=TRUE,cache=FALSE>>=
out.model2$germplasm.not.used
@

\subsubsection{Analysis of model outputs}

Once the model is run, it is necessary to check if the outputs can be taken with confidence. 
This step is needed before going ahead in the analysis (in fact, the MCMC object used in the next functions must come from \texttt{analyse.outputs}!).


<<message=TRUE,cache=FALSE>>=
# out2 = analyse.outputs(out.model2)
# The experimental design plot is done.
# The Gelman-Rubin test is running for each parameter ...
# The two MCMC for each parameter converge thanks to the Gelman-Rubin test.
# The alpha_i posterior distributions are done.
# The beta_i posterior distributions are done.
# The theta_j posterior distributions are done.
# The standardised residuals distributions are done.

load("./data_PPBstats/out2.RData") # To save time
@

\texttt{out2} is a list containing :

\begin{itemize}

\item "experimental\_design" : a plot representing the presence/abscence matrix of G $\times$ E combinaisons. 
Note that it displays only germplasms that are on at least two environments.

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
out2$data.experimental_design$plot
@
\end{figure}

\item "convergence" : a list with the plots of trace and density to check the convergence of the two MCMC only for chains that are not converging thanks to the Gelman-Rubin test \citep{gelman_inference_1992}. If all the chains converge, it is NULL

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
out2$convergence
@
\end{figure}

\item "parameter\_posteriors": a list with caterpillar plot for each $\alpha_i$, $\beta_i$ and $\theta_j$.

Below an example for $\alpha_i$.

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
p = out2$posteriors$parameter_posteriors$alpha_posteriors
grid.arrange(p[[1]], p[[2]],ncol = 2, nrow = 1)
grid.arrange(p[[3]], p[[4]],ncol = 2, nrow = 1)
@
\end{figure}


\item "standardized\_residuals" : a plot to check the normality of the residuals. If the model went well it should be between -2 and 2.

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
out2$posteriors$standardized_residuals
@
\end{figure}

\item "MCMC": a data fame resulting from the concatenation of the two MCMC for each parameter. This object can be used for further analysis. There are as many columns than parameters and as many rows than iterations/thin (the thin value is 10 by default in the models).

<<message=TRUE,cache=FALSE>>=
dim(out2$MCMC)
@

\end{itemize}

Just for fun, you compare the posterior medians and the arithmetic means for the $\alpha_i$'s.

<<message=TRUE,cache=FALSE>>=
MCMC = out2$MCMC
effects = apply(MCMC, 2, median)
alpha_i_estimated = effects[grep("alpha\\[",names(effects))]
names(alpha_i_estimated) = sapply(names(alpha_i_estimated), function(x){  
sub("\\]", "", sub("alpha\\[", "", x)) } )
 
alpha_i = tapply(PPBdata2$alpha_i, PPBdata2$germplasm, mean, na.rm = TRUE)
 
check = cbind.data.frame(alpha_i = alpha_i, alpha_i_estimated = alpha_i_estimated[names(alpha_i)])
@

Let’s have a look at the relation between both values.

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
p = ggplot(check, aes(x = alpha_i, y = alpha_i_estimated))
p + stat_smooth(method = "lm") + geom_point()
@
\end{figure}


\subsubsection{Perform cross validation studies}

This step is useful to assess the quality of the model.
This step is higly computing consuming as the FWH model is run as many time as there is value of $Y_{ij}$ (i.e. number of rows of the data set).

The complete cross validation is done with \texttt{cross.validation.FWH}: 
each Value of $Y_{ij}$ is estimated by the entire data set without this value.

The convergence is not check for each validation. 
If the parameters in the FWH converge, then it is assumed that the FWH in the cross validation converge as well.

The model is run on dataset where germplasms are in three environments at least so the smallest data set where the cross valisation is run has germplasms present in two environments at least. 

You may parallelise to gain time with the \texttt{mc.cores} argument of the function.

The number of iterations is set to 100 000 but you can change it with the \texttt{nb\_iterations} argument.

The percentage of confidence is calculated with a t-test:

\begin{displaymath}
t = \frac{m - 0}{s/\sqrt{N}}
\end{displaymath}
with,

$N$ the number of observations in the data set,

$m = \frac{1}{N} \sum\limits_{n=1}^N Y_{n} - \hat{Y_{n}}$, the average bias

$s = \sqrt{\frac{1}{N-1} \sum\limits_{n=1}^N (Y_{n} - \hat{Y_{n}})^2}$, the standard deviation of the bias

$t$ follows a Student distribution with $N-1$ degree of freedom.

The percentage of confidence (i.e. the probability $H0$: the bias is equal to zero) comes from this distribution.

A regression is also done between estimated and observed value.

Here it is bad as only 10 iterations have been done to save computing time ...

<<message=TRUE,cache=FALSE>>=
# out.cv = cross.validation.FWH(data = PPBdata2, variable = "y1", nb_iterations = 10)
load("./data_PPBstats/out.cv.RData") # to save lots of time
@

<<message=TRUE,cache=FALSE>>=
out.cv$percentage.of.confidence
@

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
out.cv$regression
@
\end{figure}



\subsubsection{Get mean comparisons}
For mean comparisons of parameters, it is the same method that presented in section \ref{mean_comp}.

<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
comp.alpha = get.mean.comparisons(out2$MCMC, "alpha")
comp.theta = get.mean.comparisons(out2$MCMC, "theta")
comp.beta = get.mean.comparisons(out2$MCMC, "beta", type = 2, threshold = 1)
@

To see the output, use \texttt{get.ggplot}.

<<message=TRUE,cache=FALSE>>=
p_barplot = get.ggplot(comp.alpha, ggplot.type = "barplot")
@

Lets' have a look at the firt values of $\alpha_i$.

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
grid.arrange(p_barplot$"alpha"[[1]], p_barplot$"alpha"[[2]] , ncol = 2, nrow = 1)
@
\end{figure}

\subsubsection{Get biplot $\beta = f(\alpha)$}

It is interessting to compare genetic effect versus sensibility to interaction.
A germplasm with an high genetic effect and a low sensitivity to interaction (i.e. close to 0) may be a good candidate to sown.

<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
comp.alpha = get.mean.comparisons(out2$MCMC, "alpha")
comp.beta = get.mean.comparisons(out2$MCMC, "beta")

g = get.ggplot(data = comp.alpha, data_2 = comp.beta, ggplot.type = "biplot-alpha-beta")
g$biplot
@


\subsubsection{Get groups of parameters}

In order to cluster environments or germplasms, you may use mulivariate analysis on a matrix with several variables in columns and parameter in rows.

This is done with \texttt{get.parameter.groups} which do a PCA on this matrix and then find cluster with the \texttt{HCPC} procedure from package \texttt{FactoMineR}: it is a K-means clustering that creates clusters of similar parameters \citep{husson_principal_2010}.
The Kmeans clustering was done on the first two axes of the PCA that represented the main information while the last axes represented mainly noise \citep{husson_principal_2010}.
The number of clusters is choosen to maximise the variance between clusters and within clusters.
For more information type \texttt{?get.parameter.groups}.

<<message=TRUE,cache=FALSE>>=
# out.model2_y1 = FWH(PPBdata2, variable = "y1")
load("./data_PPBstats/out.model2_y1.RData") # to save time

# out.model2_y2 = FWH(PPBdata2, variable = "y2")
load("./data_PPBstats/out.model2_y2.RData") # to save time

# out.model2_y3 = FWH(PPBdata2, variable = "y3")
load("./data_PPBstats/out.model2_y3.RData") # to save time
 
out2_y1 = analyse.outputs(out.model2_y1)
out2_y2 = analyse.outputs(out.model2_y2)
out2_y3 = analyse.outputs(out.model2_y3)
 
analyse.outputs.list = list(var1 = out2_y1, var2 = out2_y2, var3 = out2_y3)

clust = get.parameter.groups(analyse.outputs.list, parameter = "theta")
@

To see the output, use \texttt{get.ggplot}.
A farmer may find a germplasm that behaves well according to informations from model \ref{model1} (section \ref{section_model1}) in a farm that shares its cluster.

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
p_PCA = get.ggplot(clust, ggplot.type = "PCA")
p_PCA
@
\end{figure}



\subsubsection{Predict the past}

In order to choose a new germplasm to test on his farm, a farmer may choose a germplasm according to the value it would have obtained on his farm.

You may either get the estimated MCMC, but you will need lots of memory, or the summary statistics of the MCMC.

Due to memory issues, it may be better to choose output.format = "summary".
This allows caterpillar plots but no mean comparisons that are base on the whole MCMC.

<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
# out.predict.the.past = predict.the.past(out2, output.format = "summary")
# |==========================================================| 100%
load("./data_PPBstats/out.predict.the.past.RData") # to save time
dim(out.predict.the.past)
@


If you choose \texttt{output.format = "summary"}, it is possible to look at the results with \texttt{get.ggplot}.


<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
p_barplot_predict = get.ggplot(out.predict.the.past, ggplot.type = "barplot", 
                               nb_parameters_per_plot = 30)
p_barplot_predict$`loc-11:year-1`$`1`
@

<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
p_interaction_predict = get.ggplot(out.predict.the.past, ggplot.type = "interaction")
p_interaction_predict$`loc-46`$`1`
@


